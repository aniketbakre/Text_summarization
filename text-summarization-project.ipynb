{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2024-07-24T04:08:22.181044Z","iopub.execute_input":"2024-07-24T04:08:22.181339Z","iopub.status.idle":"2024-07-24T04:08:23.146504Z","shell.execute_reply.started":"2024-07-24T04:08:22.181312Z","shell.execute_reply":"2024-07-24T04:08:23.145365Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/samsum-dataset/samsum-train.csv\n/kaggle/input/samsum-dataset/samsum-test.csv\n/kaggle/input/samsum-dataset/samsum-validation.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"# Import required libraries\nimport pandas as pd\nimport numpy as np\n# from datasets import load_dataset\nfrom datasets import Dataset\nfrom transformers import BartForConditionalGeneration, BartTokenizer, Trainer, TrainingArguments, DataCollatorWithPadding\nimport random\n","metadata":{"execution":{"iopub.status.busy":"2024-07-24T04:08:23.148219Z","iopub.execute_input":"2024-07-24T04:08:23.148724Z","iopub.status.idle":"2024-07-24T04:08:40.525921Z","shell.execute_reply.started":"2024-07-24T04:08:23.148690Z","shell.execute_reply":"2024-07-24T04:08:40.525171Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-07-24 04:08:30.520975: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-24 04:08:30.521077: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-24 04:08:30.653153: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"# # Load the train dataset (CNN dialy mail)\n# ds = load_dataset(\"abisee/cnn_dailymail\", \"3.0.0\")\n# print(ds)\n\n\n# using samsum dataset due to less computational power\ntrain_df = pd.read_csv(\"/kaggle/input/samsum-dataset/samsum-train.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/samsum-dataset/samsum-test.csv\")\nval_df = pd.read_csv(\"/kaggle/input/samsum-dataset/samsum-validation.csv\")\n\n# converting to pandas dataframe\ntrain_dataset = Dataset.from_pandas(train_df)\nval_dataset = Dataset.from_pandas(val_df)\ntest_dataset = Dataset.from_pandas(test_df)","metadata":{"execution":{"iopub.status.busy":"2024-07-24T04:08:40.526937Z","iopub.execute_input":"2024-07-24T04:08:40.527515Z","iopub.status.idle":"2024-07-24T04:08:40.896256Z","shell.execute_reply.started":"2024-07-24T04:08:40.527488Z","shell.execute_reply":"2024-07-24T04:08:40.895346Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Load tokenizer and model\ntokenizer = BartTokenizer.from_pretrained(\"facebook/bart-base\")\nmodel = BartForConditionalGeneration.from_pretrained(\"facebook/bart-base\")","metadata":{"execution":{"iopub.status.busy":"2024-07-24T04:08:40.898281Z","iopub.execute_input":"2024-07-24T04:08:40.898598Z","iopub.status.idle":"2024-07-24T04:08:46.866650Z","shell.execute_reply.started":"2024-07-24T04:08:40.898573Z","shell.execute_reply":"2024-07-24T04:08:46.865753Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"33e69a2f6cc14ec7b92fd1c13416b78b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"15eb1deb88314ff2af335f5b2a62e896"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a1ad0e33f9d4679a41ec462e5f01129"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.72k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"722ca29d69a2403c9d3f66120d18658d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/558M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b0f5f04ad1d4c2cb0fde54e3072425b"}},"metadata":{}}]},{"cell_type":"code","source":"# Define preprocess function\ndef preprocess_function(examples):\n    # Ensure the columns are strings\n    inputs = [str(text) for text in examples[\"dialogue\"]]\n    targets = [str(text) for text in examples[\"summary\"]]\n    \n    model_inputs = tokenizer(inputs, max_length=1024, padding=\"max_length\", truncation=True)\n    labels = tokenizer(targets, max_length=1024, padding=\"max_length\", truncation=True)\n    \n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs\n\n# Apply preprocessing\ntokenized_train = train_dataset.map(preprocess_function, batched=True)\ntokenized_val = val_dataset.map(preprocess_function, batched=True)\ntokenized_test = test_dataset.map(preprocess_function, batched=True)","metadata":{"execution":{"iopub.status.busy":"2024-07-24T04:08:46.867644Z","iopub.execute_input":"2024-07-24T04:08:46.867912Z","iopub.status.idle":"2024-07-24T04:09:29.379960Z","shell.execute_reply.started":"2024-07-24T04:08:46.867890Z","shell.execute_reply":"2024-07-24T04:09:29.379062Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/14732 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"97ef40b4a92e4d958581ed587dc10a07"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/818 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be54c4f08b0442208cd07e0db324ca79"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/819 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d5595353e184d6e8c20e2ce016c8aec"}},"metadata":{}}]},{"cell_type":"code","source":"from transformers import BartTokenizer, BartForConditionalGeneration, DataCollatorForSeq2Seq, Trainer, TrainingArguments\n\n# Initialize data collator for seq2seq tasks\ndata_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n\n# Define training arguments\ntraining_args = TrainingArguments(\n    output_dir=\"./text_summarization_model\",\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=2,\n    per_device_eval_batch_size=2,\n    weight_decay=0.01,\n    save_total_limit=3,\n    num_train_epochs=3,\n    load_best_model_at_end=True,\n    fp16=True,  # Enable mixed precision\n    gradient_accumulation_steps=4,  # Accumulate gradients over 4 steps\n)\n\n# Initialize Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_train,\n    eval_dataset=tokenized_val,\n    data_collator=data_collator,\n)\n\n# Train the model\ntrainer.train()\n","metadata":{"execution":{"iopub.status.busy":"2024-07-24T04:09:48.991783Z","iopub.execute_input":"2024-07-24T04:09:48.992459Z","iopub.status.idle":"2024-07-24T06:54:31.542221Z","shell.execute_reply.started":"2024-07-24T04:09:48.992428Z","shell.execute_reply":"2024-07-24T06:54:31.541358Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.5 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.17.4"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240724_041005-03wi89of</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/aniketbakre1291-self/huggingface/runs/03wi89of' target=\"_blank\">./text_summarization_model</a></strong> to <a href='https://wandb.ai/aniketbakre1291-self/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/aniketbakre1291-self/huggingface' target=\"_blank\">https://wandb.ai/aniketbakre1291-self/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/aniketbakre1291-self/huggingface/runs/03wi89of' target=\"_blank\">https://wandb.ai/aniketbakre1291-self/huggingface/runs/03wi89of</a>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2760' max='2760' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2760/2760 2:44:03, Epoch 2/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>1.164200</td>\n      <td>0.042581</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>0.045200</td>\n      <td>0.041168</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.041900</td>\n      <td>0.040805</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\nThere were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight', 'lm_head.weight'].\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=2760, training_loss=0.24741179597550544, metrics={'train_runtime': 9880.3116, 'train_samples_per_second': 4.473, 'train_steps_per_second': 0.279, 'total_flos': 2.69259619958784e+16, 'train_loss': 0.24741179597550544, 'epoch': 2.997556339940266})"},"metadata":{}}]},{"cell_type":"code","source":"# Evaluate the model\neval_results = trainer.evaluate(eval_dataset=tokenized_test)\nprint(eval_results)","metadata":{"execution":{"iopub.status.busy":"2024-07-24T06:54:54.678146Z","iopub.execute_input":"2024-07-24T06:54:54.678990Z","iopub.status.idle":"2024-07-24T06:56:00.524627Z","shell.execute_reply.started":"2024-07-24T06:54:54.678954Z","shell.execute_reply":"2024-07-24T06:56:00.523254Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='205' max='205' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [205/205 01:05]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"{'eval_loss': 0.040996383875608444, 'eval_runtime': 65.8341, 'eval_samples_per_second': 12.44, 'eval_steps_per_second': 3.114, 'epoch': 2.997556339940266}\n","output_type":"stream"}]},{"cell_type":"code","source":"# Save the model and tokenizer to output directory\noutput_dir = './text_summarization_model'\nmodel.save_pretrained(output_dir)\ntokenizer.save_pretrained(output_dir)","metadata":{"execution":{"iopub.status.busy":"2024-07-24T06:56:26.829692Z","iopub.execute_input":"2024-07-24T06:56:26.830055Z","iopub.status.idle":"2024-07-24T06:56:27.940466Z","shell.execute_reply.started":"2024-07-24T06:56:26.830026Z","shell.execute_reply":"2024-07-24T06:56:27.939428Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"('./text_summarization_model/tokenizer_config.json',\n './text_summarization_model/special_tokens_map.json',\n './text_summarization_model/vocab.json',\n './text_summarization_model/merges.txt',\n './text_summarization_model/added_tokens.json')"},"metadata":{}}]},{"cell_type":"code","source":"\n# Zip the saved model directory\nimport shutil\nshutil.make_archive(\"/kaggle/working/text_summarization_model/checkpoint-2760\", 'zip', \"/kaggle/working/text_summarization_model/checkpoint-2760\")","metadata":{"execution":{"iopub.status.busy":"2024-07-24T07:05:47.709342Z","iopub.execute_input":"2024-07-24T07:05:47.710085Z","iopub.status.idle":"2024-07-24T07:07:19.962902Z","shell.execute_reply.started":"2024-07-24T07:05:47.710054Z","shell.execute_reply":"2024-07-24T07:07:19.961879Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/text_summarization_model/checkpoint-2760.zip'"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}